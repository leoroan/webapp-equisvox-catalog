# ğŸ§­ ARQUITECTURA FINAL 

**Objetivo real**
Tener una SPA estÃ¡tica (GitHub Pages) que muestre datos **siempre actualizados**, sin backend propio, usando:

* **Google Sheets** â†’ base de datos
* **Google Apps Script** â†’ API + orquestador
* **GitHub Actions** â†’ procesador pesado (scraping)
* **Python scraper** â†’ genera los datos
* **Front SPA** â†’ solo consume JSON

---

# 1ï¸âƒ£ Google Sheets = BDD

Creamos un **Spreadsheet** con al menos estas hojas:

### `_meta`

Control de estado del sistema

| key          | value                |
| ------------ | -------------------- |
| last_update  | 2025-12-16T03:00:00Z |
| refresh_lock | 0                    |

ğŸ‘‰ sirve para:

* saber cuÃ¡ndo fue la Ãºltima actualizaciÃ³n
* evitar ejecuciones concurrentes

---

### `xb`

La â€œtablaâ€ principal (500+ filas)

Headers (fila 1):

```
ID | Title | Original Price | Current Price | Discount % | Offer | URL | Image URL
```

ğŸ‘‰ esta hoja **ya no se edita a mano**, solo por el scraper.

---

# 2ï¸âƒ£ Google Apps Script = API + cerebro

Creamos un proyecto Apps Script **vinculado al Sheet**.

## ğŸ¯ QuÃ© hace Apps Script

### A) Expone una API HTTP (`doGet`)

Usada por:

* el front
* GitHub Actions
* lÃ³gica de refresco

---

### B) Decide si hay que refrescar datos

Endpoint:

```
?action=status
```

LÃ³gica real:

* lee `_meta.last_update`
* calcula horas desde la Ãºltima actualizaciÃ³n
* si pasÃ³ el lÃ­mite y `refresh_lock = 0`

  * pone `refresh_lock = 1`
  * dispara GitHub Action

ğŸ‘‰ **Apps Script NO scrapea**
ğŸ‘‰ solo decide *cuÃ¡ndo* scrapea alguien mÃ¡s

---

### C) Sirve datos al front (API real)

Endpoints que implementaste:

#### `/list`

```
?action=list&limit=50&offset=0
```

* lee la hoja `xb`
* devuelve JSON tipado
* soporta paginaciÃ³n

#### `/by_id`

```
?action=by_id&id=XXXX
```

* busca por columna `ID`
* devuelve un solo juego

ğŸ‘‰ acÃ¡ hiciste el ajuste clave:

* helpers devuelven **objetos**
* solo `doGet()` devuelve `TextOutput`

---

# 3ï¸âƒ£ GitHub Actions = motor de ejecuciÃ³n

Problema:

* Colab **no puede ejecutarse solo**
* Apps Script **no puede scrapear fuerte**
* GitHub Actions **sÃ­ puede** (gratis y estable)

ğŸ‘‰ por eso usamos Actions como **worker**.

---

## QuÃ© hace la Action

* se ejecuta por `repository_dispatch`
* corre en Ubuntu
* instala Python + requirements
* ejecuta tu script scraper

Y listo.

---

## CÃ³mo se dispara

Apps Script hace un `POST` a GitHub usando:

* un **Personal Access Token**
* guardado como **secret**
* endpoint `repository_dispatch`

ğŸ‘‰ eso fue todo el tema de tokens
ğŸ‘‰ **NO hay OAuth, NO hay login de usuarios**

---

# 4ï¸âƒ£ Python Scraper = ETL

Tu script Python ya existÃ­a.
Lo adaptamos para que:

### Antes

```
scrape â†’ CSV
```

### Ahora

```
scrape â†’ Google Sheets
```

CÃ³mo:

* `gspread`
* credenciales de servicio (JSON)
* secret `GOOGLE_CREDENTIALS` en GitHub

ğŸ‘‰ el CSV dejÃ³ de existir
ğŸ‘‰ Sheets pasÃ³ a ser la Ãºnica fuente de verdad

---

# 5ï¸âƒ£ GitHub Secrets (lo que realmente usaste)

### En GitHub â†’ Settings â†’ Secrets â†’ Actions

Usaste **solo estos**:

| Secret               | Para quÃ©                    |
| -------------------- | --------------------------- |
| `TOKEN_TRIGGER`      | Apps Script â†’ GitHub Action |
| `GOOGLE_CREDENTIALS` | Python â†’ Google Sheets      |

ğŸ‘‰ **NO usaste Google Cloud directamente**
ğŸ‘‰ solo una **Service Account** mÃ­nima para Sheets

---

# 6ï¸âƒ£ Frontend SPA (GitHub Pages)

Antes:

* consumÃ­a `sample_data.csv`
* parseaba texto

Ahora:

* consume Apps Script API
* recibe JSON limpio

Cambio real:

* reemplazaste `CsvDataSource`
* por `ApiDataSource`

Nada mÃ¡s.

ğŸ‘‰ filtros, sort, paginaciÃ³n **no cambiaron**

---

# 7ï¸âƒ£ Flujo completo (de punta a punta)

```
Usuario abre la web
        â†“
Front llama /?action=status
        â†“
Apps Script revisa _meta
        â†“
(si estÃ¡ viejo)
  â†’ dispara GitHub Action
        â†“
GitHub Action corre Python
        â†“
Python scrapea
        â†“
Python escribe en Sheet (xb)
        â†“
Python actualiza _meta
        â†“
Front llama /?action=list
        â†“
JSON â†’ render
```

---

# ğŸ§  Lo importante (para que no se te vuelva a mezclar)

* **Sheets no es backend**, es storage
* **Apps Script no es worker**, es orquestador + API
* **GitHub Actions no es backend**, es batch processor
* **Front no decide nada**, solo lee

---
